# ğŸ˜ï¸ Slum Detection Model

**Advanced Deep Learning Pipeline for Satellite Image Slum Detection**

A comprehensive PyTorch-based solution for detecting informal settlements (slums) from 120Ã—120 RGB satellite image tiles using state-of-the-art semantic segmentation models.

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train the Model
```bash
# Quick development training
python scripts/train.py --model balanced --training development --data standard

# Production training with high accuracy
python scripts/train.py --model accurate --training production --data heavy_augmentation
```

### 3. Monitor Training
Check `experiments/` directory for:
- Training logs and metrics
- Model checkpoints
- Visualization plots
- Configuration files

## ğŸ“ Project Structure

```
slum-detection-model/
â”œâ”€â”€ ğŸ“Š data/                    # Dataset (120x120 RGB tiles)
â”‚   â”œâ”€â”€ train/images/          # Training satellite images
â”‚   â”œâ”€â”€ train/masks/           # Training segmentation masks  
â”‚   â”œâ”€â”€ val/images/            # Validation images
â”‚   â”œâ”€â”€ val/masks/             # Validation masks
â”‚   â”œâ”€â”€ test/images/           # Test images
â”‚   â””â”€â”€ test/masks/            # Test masks
â”‚
â”œâ”€â”€ ğŸ—ï¸ models/                  # Model architectures
â”‚   â”œâ”€â”€ __init__.py           # Model package
â”‚   â”œâ”€â”€ unet.py               # UNet variants (ResNet, EfficientNet)
â”‚   â”œâ”€â”€ losses.py             # Loss functions (Dice, Focal, Combined)
â”‚   â””â”€â”€ metrics.py            # Evaluation metrics (IoU, F1, etc.)
â”‚
â”œâ”€â”€ âš™ï¸ config/                  # Configuration management
â”‚   â”œâ”€â”€ __init__.py           # Config package
â”‚   â”œâ”€â”€ model_config.py       # Model hyperparameters
â”‚   â”œâ”€â”€ training_config.py    # Training settings
â”‚   â””â”€â”€ data_config.py        # Data preprocessing config
â”‚
â”œâ”€â”€ ğŸ› ï¸ utils/                   # Utilities and helpers
â”‚   â”œâ”€â”€ __init__.py           # Utils package
â”‚   â”œâ”€â”€ dataset.py            # Dataset class with filtering
â”‚   â”œâ”€â”€ transforms.py         # Data augmentation pipeline
â”‚   â”œâ”€â”€ visualization.py      # Training/result visualization
â”‚   â””â”€â”€ checkpoint.py         # Model checkpoint management
â”‚
â”œâ”€â”€ ğŸ¯ scripts/                 # Main execution scripts
â”‚   â”œâ”€â”€ train.py              # Training script with experiment management
â”‚   â”œâ”€â”€ test.py               # Model evaluation and testing
â”‚   â”œâ”€â”€ inference.py          # Single image prediction
â”‚   â””â”€â”€ export_model.py       # Model export (ONNX, TorchScript)
â”‚
â”œâ”€â”€ ğŸ§ª experiments/             # Training experiments
â”‚   â”œâ”€â”€ logs/                 # Training logs
â”‚   â”œâ”€â”€ checkpoints/          # Model weights
â”‚   â”œâ”€â”€ results/              # Test results and plots
â”‚   â””â”€â”€ configs/              # Experiment configurations
â”‚
â”œâ”€â”€ ğŸ“ˆ analysis/               # Dataset analysis scripts
â”‚   â”œâ”€â”€ comprehensive_dataset_analysis.py
â”‚   â”œâ”€â”€ FINAL_DATASET_ANALYSIS_REPORT.txt
â”‚   â””â”€â”€ [various analysis scripts...]
â”‚
â”œâ”€â”€ ğŸ“Š charts/                 # Model analysis and visualization
â”‚   â”œâ”€â”€ model_analysis.py     # Comprehensive model analysis
â”‚   â”œâ”€â”€ quick_analysis.py     # Fast post-training evaluation
â”‚   â”œâ”€â”€ post_training_analysis.py # Automated analysis pipeline
â”‚   â”œâ”€â”€ example_analysis.py   # Usage examples
â”‚   â””â”€â”€ README.md             # Analysis documentation
â”‚
â””â”€â”€ ğŸ“‹ requirements.txt        # Python dependencies
```

## ğŸ¯ Key Features

### ğŸ—ï¸ **Advanced Model Architectures**
- **UNet**: Standard U-Net with multiple encoder options
- **UNet++**: Nested U-Net for improved feature representation  
- **DeepLabV3+**: Atrous convolutions for multi-scale context
- **Encoders**: ResNet, EfficientNet, MobileNet, DenseNet

### ğŸ”¥ **Sophisticated Loss Functions**
- **Combined Loss**: BCE + Dice + Focal for optimal training
- **Focal Loss**: Handles class imbalance (slum vs non-slum)
- **Tversky Loss**: Precision/recall balance control
- **Dice Loss**: Overlap optimization

### ğŸ“Š **Comprehensive Metrics**
- **IoU (Jaccard)**: Primary segmentation metric
- **Dice Score**: Overlap measurement
- **Precision/Recall**: Class-specific performance
- **F1 Score**: Balanced performance measure

### ğŸ”„ **Advanced Data Augmentation**
- **Geometric**: Rotation, flipping, scaling, elastic transforms
- **Color**: Brightness, contrast, saturation adjustments  
- **Noise**: Gaussian noise, blur for robustness
- **Advanced**: Grid distortion, cutout, mixup

### âš¡ **Training Optimizations**
- **Mixed Precision**: Faster training with AMP
- **Learning Rate Scheduling**: Cosine annealing, plateau reduction
- **Early Stopping**: Prevent overfitting
- **Gradient Clipping**: Training stability

### ğŸ“Š **Model Analysis & Visualization**
- **Automatic Analysis**: Post-training evaluation with confusion matrices, ROC curves
- **Comprehensive Charts**: Threshold analysis, performance metrics, prediction samples
- **Multiple Formats**: Quick analysis (4 charts) or comprehensive (15+ charts)
- **Performance Metrics**: AUC-ROC, Precision-Recall, F1-Score optimization
- **Visual Debugging**: Sample predictions with ground truth comparison

## ğŸ›ï¸ Configuration Presets

### Model Configurations
```python
# Fast inference
python scripts/train.py --model fast

# Balanced accuracy/speed  
python scripts/train.py --model balanced

# Highest accuracy
python scripts/train.py --model accurate

# Lightweight deployment
python scripts/train.py --model lightweight
```

### Training Configurations
```python
# Quick testing (10 epochs)
python scripts/train.py --training quick_test

# Development (50 epochs)
python scripts/train.py --training development

# Production training (150 epochs)
python scripts/train.py --training production

# High precision focus
python scripts/train.py --training high_precision

# High recall focus  
python scripts/train.py --training high_recall
```

### Data Configurations
```python
# Minimal augmentation
python scripts/train.py --data minimal

# Standard augmentation
python scripts/train.py --data standard

# Heavy augmentation
python scripts/train.py --data heavy_augmentation

# Production with TTA
python scripts/train.py --data production
```

## ğŸ“‹ Dataset Requirements

### ğŸ¯ **Class Mapping**
- **Slum Class**: RGB (250, 235, 185) â†’ Binary 1
- **Non-Slum**: All other RGB values â†’ Binary 0

### ğŸ“Š **Dataset Statistics** 
- **Total Images**: 8,910 masks analyzed
- **Slum Coverage**: 1,657 masks contain slums (18.6%)
- **Image Size**: 120Ã—120 RGB tiles
- **Mask Format**: PNG with RGB encoding

### ğŸ¨ **Data Quality**
- âœ… **Excellent Coverage**: Sufficient slum examples for training
- âœ… **Balanced Distribution**: 0-100% slum coverage range  
- âœ… **Clean Encoding**: Consistent RGB class mapping
- âœ… **Ready for Training**: No preprocessing required

## ğŸš€ Training Examples

### Basic Training
```bash
# Train with default settings
python scripts/train.py
```

### Custom Training
```bash
# High-accuracy model with heavy augmentation
python scripts/train.py \
  --model accurate \
  --training production \
  --data heavy_augmentation \
  --experiment "high_accuracy_v1"
```

### Resume Training
```bash
# The system automatically handles checkpointing
# Just rerun the same command to resume from last checkpoint
python scripts/train.py --experiment "my_experiment"
```

## ğŸ“ˆ Monitoring Training

### Real-time Monitoring
- **Console Logs**: Batch-level progress and metrics
- **Plots**: Automatically generated training curves
- **Checkpoints**: Best models saved automatically

### 4. Analyze Results
```bash
# Automatic analysis after training (built-in)
# Or run manual analysis:

# Quick analysis
python charts/post_training_analysis.py --auto-find

# Comprehensive analysis with all charts
python charts/post_training_analysis.py --checkpoint experiments/*/checkpoints/best_model.pth --analysis-type comprehensive

# Quick example
python charts/example_analysis.py
```

### Result Analysis
```bash
# Check experiment results
ls experiments/[experiment_name]/

# View generated charts
ls charts/analysis_*/
```

## ğŸ† Expected Performance

Based on dataset analysis, expect:
- **IoU Score**: 0.75-0.85 for well-trained models
- **Dice Score**: 0.80-0.90 for optimal overlap
- **F1 Score**: 0.80-0.90 for balanced performance
- **Training Time**: 2-4 hours on modern GPU

## ğŸ› ï¸ Customization

### Adding New Models
1. Implement in `models/unet.py`
2. Add configuration in `config/model_config.py`
3. Update factory function

### Custom Loss Functions  
1. Implement in `models/losses.py`
2. Add to `create_loss()` factory
3. Configure in training config

### New Augmentations
1. Add to `utils/transforms.py`
2. Configure in `config/data_config.py`
3. Test with visualization utilities

## ğŸ“ License

This project is designed for satellite image analysis and slum detection research. Please ensure compliance with satellite imagery usage terms and local regulations.

---

**ğŸ¯ Ready to detect slums with state-of-the-art deep learning!**

For questions or issues, check the experiment logs or configuration files for detailed settings and results.
